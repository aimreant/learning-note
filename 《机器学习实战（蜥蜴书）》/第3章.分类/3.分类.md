# 《机器学习实战》-分类

## 性能考核

### 考核指标

- 准确率

	- 实践：交叉验证

		- 自动：cross_val_score，返回评估分数
		- 手动：结合sklearn.model_selection.StratifiedKFold执行分层抽样

	- 缺点：在偏斜数据集（skewed dataset），即某些类比其他类更为频繁，不能很好地评估分类器

- 精度和召回率（混淆矩阵）

	- 思路：统计A类实例被分成为B类的次数
	- 实践

		- 1. 使用cross_val_predict，返回折叠的干净预测
		- 2. 使用sklearn.metrics.confusion_matrix获得混淆矩阵
		- 混淆矩阵：[[真负类TN, 假正类FP][假负类FN, 真正类TP]]

	- 概念

		- 精度=TP/（TP+FP），预测的TP+FP个中，只有TP个是对的
		- 召回率=TP/（TP+FN），本应预测TP+FN个，只预测出TP个
		- F1分数

			- 概念：F1分数是精度和召回率的协波平均数。协波平均数会给较低的值更高的权重。因此只有当两个数都高，F1才会高。
			- 公式：1= 2/(1/精度+1/召回)= TP/(TP+(FN+FP)/2)

	- 场景

		- 高召回低精度场景：如小偷监控
		- 低召回高精度场景：如色情视频过滤

	- 权衡

		- 随着分类阈值变化，精度召回可能会“此起彼伏”
		- 选择最佳阈值

			- 可以通过precision_recall_curve()计算所有可能阈值的精度召回。召回曲线会比精度曲线平滑。
			- 绘制召回-精度的函数图

- ROC（受试者工作特征）曲线

	- 概念

		- 真正类率TPR，召回
		- 假正类率FPR，被错误分为正类的负类实例比率， 
   =1-正确分为负类的负类实例比率 =1-特异度TNR
		- AUC：ROC曲线下的面积

	- 权衡

		- 召回TPR越高，假正类FPR就越多
		- ROC离斜率=1的线越远，越优秀。因此AOC越大，分类器越好

## 模型改进

### 超参数微调

### 错误分析

- 通过混淆矩阵分析错误率

	- 1.计算出混淆矩阵
	- 2.混淆矩阵都除以相应类别的数量
	- 3.对角线填充0
	- 4.通过亮暗鉴别正确错误率
	- 5.对错误项改进

		- 补充数据集
		- 开发新特征分类器

## 分类器

### 二分类

- 随机梯度下降SGD分类器

	- 在训练时，完全随机（可通过设置random_state参数复现）
	- 能有效处理非常大型的数据集
	- 非常适合在线学习

### 多分类

- 使用策略能将几个二分类器实现多分类

	- OVA一对多
	- OVO一对一

### 多标签分类

### 多输出分类

## 数据集

### MNIST

- sklearn.datasets.fetch_mldata可下载
- 6w个训练集、1w个测试集
- np.random.permutation可洗牌

*XMind: ZEN - Trial Version*